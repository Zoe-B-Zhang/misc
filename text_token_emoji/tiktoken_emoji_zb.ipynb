{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziirFV9PaG-T",
        "outputId": "da4f5a45-f615-4c52-e2a9-30c407ac097b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.12.1-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from emoji) (4.12.2)\n",
            "Downloading emoji-2.12.1-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.12.1\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken\n",
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# init the GPT-4 Tokenizer\n",
        "import tiktoken\n",
        "enc = tiktoken.encoding_for_model(\"gpt-4\")\n",
        "print(enc.n_vocab) # number of tokens in total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57wUOMOhaL2y",
        "outputId": "241b06e2-73f2-443e-98ed-ee09ad37ccc1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# init the emojis\n",
        "import emoji\n",
        "emojis = list(emoji.EMOJI_DATA.keys())\n",
        "import random\n",
        "random.seed(15)\n",
        "random.shuffle(emojis)\n",
        "print(len(emoji.EMOJI_DATA)) # number of possible emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IODCjlnLeNjh",
        "outputId": "f1476a60-da29-482d-a5ea-83a5bc1b642f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_tokens(text, max_per_row=10):\n",
        "    ids = enc.encode(text)\n",
        "    unique_tokens = set(ids)\n",
        "    # map all tokens we see to a unique emoji\n",
        "    id_to_emoji = {id: emoji for emoji, id in zip(emojis, unique_tokens)}\n",
        "    # do the translation\n",
        "    lines = []\n",
        "    for i in range(0, len(ids), max_per_row):\n",
        "        lines.append(''.join([id_to_emoji[id] for id in ids[i:i+max_per_row]]))\n",
        "    out = '\\n'.join(lines)\n",
        "    return out, id_to_emoji"
      ],
      "metadata": {
        "id": "lkYaY1Kw3W07"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"How many letters 'r' in the word 'strawberry'?\"\"\"\n",
        "print(text_to_tokens(text, max_per_row=20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75OlT3yhf9p5",
        "outputId": "49c7022a-0c17-4860-cd50-d6d39c3df590"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('🧑\\u200d🦽👩🏿\\u200d❤️\\u200d💋\\u200d👨🏻🤾🏻\\u200d♀️🙍\\u200d♀️🤙🏻🧑🏾\\u200d🦼\\u200d➡️✌🏿💂📏🙍\\u200d♀️🈴🧎\\u200d♀🍏🧑\\u200d🦼\\u200d➡️', {675: '🧎\\u200d♀', 3492: '📏', 12197: '🤾🏻\\u200d♀️', 6: '🧑🏾\\u200d🦼\\u200d➡️', 15717: '🍏', 364: '🙍\\u200d♀️', 304: '✌🏿', 81: '🤙🏻', 496: '🈴', 71090: '🧑\\u200d🦼\\u200d➡️', 4438: '🧑\\u200d🦽', 279: '💂', 1690: '👩🏿\\u200d❤️\\u200d💋\\u200d👨🏻'})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc.encode(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMHXKsahgBg-",
        "outputId": "1c121192-fe92-4a21-9b72-ac3be3504183"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4438, 1690, 12197, 364, 81, 6, 304, 279, 3492, 364, 496, 675, 15717, 71090]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokens_to_text(emoji_text, id_to_emoji):\n",
        "    emoji_to_id = {v: k for k, v in id_to_emoji.items()}\n",
        "    #print(emoji_to_id)\n",
        "    # Convert emoji_text to a list of emojis\n",
        "    emojis_in_text = emoji.emoji_list(emoji_text)\n",
        "    #print(emojis_in_text)\n",
        "    ids = []\n",
        "    for item in emojis_in_text:\n",
        "        char = item['emoji']\n",
        "        if char in emoji_to_id:\n",
        "            ids.append(emoji_to_id[char])\n",
        "        else:\n",
        "            raise ValueError(f\"Emoji {char} not found in the mapping\")\n",
        "    text = enc.decode(ids)\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "jOrEJylk-vmJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = \"\"\"your words \"\"\"\n",
        "emoji_seq, emoji_ids = text_to_tokens(words, max_per_row=15)\n",
        "print(\"Emoji Sequence:\\n\", emoji_seq)\n",
        "print(\"Encoded Tokens:\\n\", enc.encode(words))\n",
        "print(\"Emoji to Token Mapping:\\n\", emoji_ids)\n",
        "print(\"Decoded Text:\\n\", tokens_to_text(emoji_seq, emoji_ids))"
      ],
      "metadata": {
        "id": "R_g7BtOU1IYy",
        "outputId": "8c968d6f-dd7c-48ef-ce3b-f36108ecbbdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emoji Sequence:\n",
            " 🤾🏻‍♀️🧎‍♀📏\n",
            "Encoded Tokens:\n",
            " [22479, 4339, 220]\n",
            "Emoji to Token Mapping:\n",
            " {4339: '🧎\\u200d♀', 220: '📏', 22479: '🤾🏻\\u200d♀️'}\n",
            "Decoded Text:\n",
            " your words \n"
          ]
        }
      ]
    }
  ]
}